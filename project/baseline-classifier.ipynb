{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda: True\n"
     ]
    }
   ],
   "source": [
    "# %load utils.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print('Cuda:', torch.cuda.is_available())\n",
    "torch.manual_seed(0)\n",
    "#torch.set_deterministic(True)\n",
    "np.random.seed(0)\n",
    "\n",
    "INDIR = '../../input/'\n",
    "OUTDIR = '../../output'\n",
    "N_IN_CHANNELS = 3 # RGB\n",
    "N_CLASSES = 2 # binary classification\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 96\n",
    "CROP_SIZE = 64\n",
    "\n",
    "def imshow(x):\n",
    "    img = x.data.cpu().permute(1, 2, 0).numpy()\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.annotations.id[index] + '.tif'\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        y_label = torch.tensor(self.annotations.label[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)\n",
    "\n",
    "class ConditionalConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim, n_in_channels, n_classes):\n",
    "        super(ConditionalConvVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        n_channels = 16 # tuneable hyperparam\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(n_in_channels + n_classes, n_channels, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels, n_channels * 2, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels * 2, n_channels * 4, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels * 4, n_channels * 8, 4, 2, 1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.flat_dim = n_channels * 8 * 4 * 4\n",
    "\n",
    "        self.mu = nn.Linear(self.flat_dim, latent_dim)\n",
    "        self.logvar = nn.Linear(self.flat_dim, latent_dim)\n",
    "\n",
    "        self.decoder_fc = nn.Linear(latent_dim + n_classes, self.flat_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_channels * 8, n_channels * 4, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(n_channels * 4, n_channels * 2, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(n_channels * 2, n_channels, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(n_channels, n_in_channels, 4, 2, 1),\n",
    "        )\n",
    "\n",
    "    def encode(self, input):\n",
    "        # implementation goes here\n",
    "        x = self.encoder(input)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def sample(self, mu, logvar):\n",
    "        # implementation goes here\n",
    "        epsilon = torch.normal(0., 1., size=mu.size()).cuda()\n",
    "        std = torch.exp(logvar * 0.5)\n",
    "        z = epsilon * std + mu\n",
    "        return z\n",
    "\n",
    "    def decode(self, input):\n",
    "        # implementation goes here\n",
    "        out = self.decoder_fc(input)\n",
    "        out = out.reshape(-1, self.n_channels * 8, 4, 4)\n",
    "        out = self.decoder(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        y must be one-hot\n",
    "        \"\"\"\n",
    "        # add n_classes as additional channels\n",
    "        # num_per_batch x n_classes x 1 x 1\n",
    "        channels = y.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        x = torch.cat((x, channels), dim=1)\n",
    "\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.sample(mu, logvar)\n",
    "        z = torch.cat((z, y), dim=1)\n",
    "\n",
    "        out = self.decode(z)\n",
    "        return mu, logvar, out\n",
    "\n",
    "    def generate(self, n, y):\n",
    "        \"\"\"\n",
    "        y must be one-hot and be of length n\n",
    "        \"\"\"\n",
    "        z = torch.randn(n, self.latent_dim).cuda()\n",
    "        z = torch.cat((z, y), dim=1)\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "def vae_loss(x, out, mu, logvar, beta=1):\n",
    "    # implementation goes here\n",
    "    recons_loss = ((out - x) * (out - x)).sum()\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    loss = recons_loss + beta * kld_loss\n",
    "    return recons_loss, kld_loss, loss\n",
    "\n",
    "class ConditionalConvGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, n_in_channels, n_classes, img_size):\n",
    "        \"\"\"\n",
    "        assume img has same height and width\n",
    "        \"\"\"\n",
    "        super(ConditionalConvGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        n_channels = 16 # tuneable hyperparam\n",
    "        self.n_channels = n_channels\n",
    "        self.emb_size = 128\n",
    "        self.flat_dim = n_channels * 8 * 4 * 4\n",
    "\n",
    "        # to embed noise\n",
    "        self.emb = nn.Embedding(n_classes, self.emb_size)\n",
    "        self.decoder_fc = nn.Linear(latent_dim + self.emb_size, self.flat_dim)\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_channels * 8, n_channels * 4, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(n_channels * 4, n_channels * 2, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(n_channels * 2, n_channels, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(n_channels, n_in_channels, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "    def decode(self, input):\n",
    "        # implementation goes here\n",
    "        out = self.decoder_fc(input)\n",
    "        out = out.reshape(-1, self.n_channels * 8, 4, 4)\n",
    "        out = self.network(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, n, y):\n",
    "        \"\"\"\n",
    "        y must be scalar labels\n",
    "        \"\"\"\n",
    "        z = torch.randn(n, self.latent_dim).cuda()\n",
    "        embed = self.emb(y)\n",
    "        z = torch.cat((z, embed), dim=1)\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "class ConditionalConvDiscriminator(nn.Module):\n",
    "    def __init__(self, latent_dim, n_in_channels, n_classes, img_size):\n",
    "        super(ConditionalConvDiscriminator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        n_channels = 16\n",
    "        self.n_channels = n_channels\n",
    "        self.flat_dim = n_channels * 8 * 4 * 4\n",
    "        self.n_in_channels = n_in_channels\n",
    "\n",
    "        # to embed class labels\n",
    "        self.emb = nn.Embedding(n_classes, img_size * img_size)\n",
    "        self.network = nn.Sequential(\n",
    "            # one more channel from label\n",
    "            nn.Conv2d(n_in_channels + 1, n_channels, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels, n_channels * 2, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels * 2, n_channels * 4, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels * 4, n_channels * 8, 4, 2, 1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flat_dim, 1) # scalar output\n",
    "            # no need for sigmoid as we are using BCEWithLogitsLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # implementation goes here\n",
    "        embed = self.emb(y).view(y.shape[0], 1, x.shape[-2], x.shape[-1])\n",
    "        x = torch.cat((x, embed), dim=1)\n",
    "        out = self.network(x)\n",
    "        return out\n",
    "\n",
    "def create_classifier(n_in_channels, n_channels=16):\n",
    "    flat_dim = n_channels * 8 * 4 * 4\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(n_in_channels, n_channels, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels, n_channels * 2, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels * 2, n_channels * 4, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels * 4, n_channels * 8, 4, 2, 1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat_dim, 1),\n",
    "            nn.Sigmoid() # scalar output, use BCELoss\n",
    "        )\n",
    "    return model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(n_in_channels, n_channels=16):\n",
    "    flat_dim = n_channels * 8 * 4 * 4 \n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(n_in_channels, n_channels, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels, n_channels * 2, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels * 2, n_channels * 4, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels * 4, n_channels * 8, 4, 2, 1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat_dim, 1),\n",
    "            nn.Sigmoid() # scalar output, use BCELoss\n",
    "        )\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_classifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '../../input/'\n",
    "N_IN_CHANNELS = 3 # RGB\n",
    "N_CLASSES = 2 # binary classification\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 96\n",
    "CROP_SIZE = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(CROP_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = TumorDataset(DIR + 'tumor_train_labels.csv',\n",
    "                      DIR + 'tumor_data/', transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-4, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = '../../output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(epoch, model, opt, criterion, train_loader, dev_loader, writer):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        labels = labels.cuda()\n",
    "        preds = model(data)\n",
    "        loss = criterion(preds.squeeze(), labels.float())\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    # end of epoch, eval on dev and record stats\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # a single batch\n",
    "        for data, labels in dev_loader:\n",
    "            x = data.cuda()\n",
    "            y = labels.cuda()\n",
    "            preds = model(x).squeeze()\n",
    "            loss = criterion(preds, y.float())\n",
    "            dev_auc = roc_auc_score(labels, preds.cpu())\n",
    "    writer.add_scalars('loss', \n",
    "                       {'train': epoch_loss, 'dev': loss.item()},\n",
    "                       epoch)\n",
    "    writer.add_scalar('AUC/dev', dev_auc, epoch)\n",
    "    # save model\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'opt_state_dict': opt.state_dict()\n",
    "            }, \n",
    "        os.path.join(OUTDIR, EXPERIMENT, 'model_{}.pth'.format(epoch)))\n",
    "    return dev_auc # save model with best dev auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = 'doughnut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(os.path.join(OUTDIR, EXPERIMENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, _ = random_split(dataset, [10, 10, len(dataset)-20],\n",
    "                          generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_SIZE = len(dataset) // 5\n",
    "DEV_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "dev_loader = DataLoader(dataset=dev, batch_size=DEV_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = 0\n",
    "for epoch in range(10):\n",
    "    dev_auc = train_classifier(epoch, model, opt, criterion, train_loader, dev_loader, writer)\n",
    "    if dev_auc > best_auc: # save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'opt_state_dict': opt.state_dict()\n",
    "            }, \n",
    "        os.path.join(OUTDIR, EXPERIMENT, 'best_model.pth'))\n",
    "        best_auc = dev_auc \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = torch.load(os.path.join(OUTDIR, EXPERIMENT, 'best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(stuff['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TumorDataset(DIR + 'tumor_test_labels.csv',\n",
    "                      DIR + 'tumor_data/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (7): Flatten()\n",
       "  (8): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  (9): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset),\n",
    "                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # a single batch\n",
    "    for data, labels in test_loader:\n",
    "        x = data.cuda()\n",
    "        y = labels.cuda()\n",
    "        preds = model(x).squeeze()\n",
    "        loss = criterion(preds, y.float())\n",
    "        auc = roc_auc_score(labels, preds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
