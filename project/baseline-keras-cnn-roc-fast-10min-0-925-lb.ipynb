{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6de38c0ff88b6738c5c8751c722c9b489602d88"
   },
   "source": [
    "# Baseline Keras CNN with 160k samples\n",
    "Heavily inspired by https://www.kaggle.com/hrmello/cnn-classification-80-accuracy\n",
    "\n",
    "Thanks to @Marsh for https://www.kaggle.com/vbookshelf/cnn-how-to-use-160-000-images-without-crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from glob import glob \n",
    "from skimage.io import imread\n",
    "import gc\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../../input/'\n",
    "OUTDIR = '../../histo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d06b98f87cfa19e2548b0d3a558128d563942e1b"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../input/train/ec513dee6b0e06af63f234ce1a0f...</td>\n",
       "      <td>ec513dee6b0e06af63f234ce1a0f62002f944ffd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../input/train/f908e555363ed81f4fa3713e2851...</td>\n",
       "      <td>f908e555363ed81f4fa3713e2851a03e75d14c0a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../input/train/0d12a52062cd967583f4cd223498...</td>\n",
       "      <td>0d12a52062cd967583f4cd223498fe37f8a2885b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  ../../input/train/ec513dee6b0e06af63f234ce1a0f...   \n",
       "1  ../../input/train/f908e555363ed81f4fa3713e2851...   \n",
       "2  ../../input/train/0d12a52062cd967583f4cd223498...   \n",
       "\n",
       "                                         id  label  \n",
       "0  ec513dee6b0e06af63f234ce1a0f62002f944ffd      1  \n",
       "1  f908e555363ed81f4fa3713e2851a03e75d14c0a      1  \n",
       "2  0d12a52062cd967583f4cd223498fe37f8a2885b      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tile_dir = DATADIR + 'train/'\n",
    "df = pd.DataFrame({'path': glob(os.path.join(base_tile_dir,'*.tif'))})\n",
    "df['id'] = df.path.map(lambda x: x.split('/')[4].split(\".\")[0])\n",
    "labels = pd.read_csv(DATADIR + \"train_labels.csv\")\n",
    "df_data = df.merge(labels, on = \"id\")\n",
    "\n",
    "# removing this image because it caused a training error previously\n",
    "df_data = df_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
    "\n",
    "# removing this image because it's black\n",
    "df_data = df_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0bfaeb9d367e1b720fd81623e9248c3ff7bb0b5e"
   },
   "source": [
    "# Split X and y in train/test and build folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "d60413a93a292379227e2b8979d2abeed70ed718"
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1000 # load 1k negative examples\n",
    "\n",
    "# take a random sample of class 0 with size equal to num samples in class 1\n",
    "df_0 = df_data[df_data['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n",
    "# filter out class 1\n",
    "df_1 = df_data[df_data['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n",
    "\n",
    "# concat the dataframes\n",
    "df_data = shuffle(pd.concat([df_0, df_1], axis=0).reset_index(drop=True))\n",
    "\n",
    "# train_test_split # stratify=y creates a balanced validation set.\n",
    "y = df_data['label']\n",
    "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n",
    "\n",
    "# Create directories\n",
    "train_path = OUTDIR + 'train'\n",
    "valid_path = OUTDIR + 'dev'\n",
    "test_path = DATADIR + 'test'\n",
    "for fold in [train_path, valid_path]:\n",
    "    for subf in [\"0\", \"1\"]:\n",
    "        os.makedirs(os.path.join(fold, subf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "e85d943cfc261cca54b34550554549244f947400"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>348dac33612805543578f6abd6726d95d9a8c4d8</th>\n",
       "      <td>../../input/train/348dac33612805543578f6abd672...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb78940aa0c4dbfe26b085a043b9e661e97ad7bf</th>\n",
       "      <td>../../input/train/fb78940aa0c4dbfe26b085a043b9...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eafd7247f69868909706e28dc0d8d30e9247c4ef</th>\n",
       "      <td>../../input/train/eafd7247f69868909706e28dc0d8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1aeb6c98daf65ae63b48ba26ecc14adc06bbd4ae</th>\n",
       "      <td>../../input/train/1aeb6c98daf65ae63b48ba26ecc1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d132fa3cad65a8275d80af1924f4e31da90bcf8a</th>\n",
       "      <td>../../input/train/d132fa3cad65a8275d80af1924f4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       path  \\\n",
       "id                                                                                            \n",
       "348dac33612805543578f6abd6726d95d9a8c4d8  ../../input/train/348dac33612805543578f6abd672...   \n",
       "fb78940aa0c4dbfe26b085a043b9e661e97ad7bf  ../../input/train/fb78940aa0c4dbfe26b085a043b9...   \n",
       "eafd7247f69868909706e28dc0d8d30e9247c4ef  ../../input/train/eafd7247f69868909706e28dc0d8...   \n",
       "1aeb6c98daf65ae63b48ba26ecc14adc06bbd4ae  ../../input/train/1aeb6c98daf65ae63b48ba26ecc1...   \n",
       "d132fa3cad65a8275d80af1924f4e31da90bcf8a  ../../input/train/d132fa3cad65a8275d80af1924f4...   \n",
       "\n",
       "                                          label  \n",
       "id                                               \n",
       "348dac33612805543578f6abd6726d95d9a8c4d8      0  \n",
       "fb78940aa0c4dbfe26b085a043b9e661e97ad7bf      1  \n",
       "eafd7247f69868909706e28dc0d8d30e9247c4ef      0  \n",
       "1aeb6c98daf65ae63b48ba26ecc14adc06bbd4ae      0  \n",
       "d132fa3cad65a8275d80af1924f4e31da90bcf8a      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the id as the index in df_data\n",
    "df_data.set_index('id', inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "c6683c986522a604dc1a715687b1d1c621628e94"
   },
   "outputs": [],
   "source": [
    "for image in df_train['id'].values:\n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image + '.tif'\n",
    "    label = str(df_data.loc[image,'label']) # get the label for a certain image\n",
    "    src = os.path.join(DATADIR + 'train', fname)\n",
    "    dst = os.path.join(train_path, label, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "for image in df_val['id'].values:\n",
    "    fname = image + '.tif'\n",
    "    label = str(df_data.loc[image,'label']) # get the label for a certain image\n",
    "    src = os.path.join(DATADIR + 'train', fname)\n",
    "    dst = os.path.join(valid_path, label, fname)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "145ef9177524908eb5656fd1deb55a82aeb01973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SIZE = 96\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='binary')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='binary')\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "test_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='binary',\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "037766b4d6d71232ff280ee04aee45671db93b7a"
   },
   "source": [
    "# Define the model \n",
    "**Model structure (optimizer: Adam):**\n",
    "\n",
    "* In \n",
    "* [Conv2D*3 -> MaxPool2D -> Dropout] x3 --> (filters = 16, 32, 64)\n",
    "* Flatten \n",
    "* Dense (256) \n",
    "* Dropout \n",
    "* Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "1d252eb588aaf888171ff82b332efd4a0880cab3"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(0.01), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56a7cce49809eae68d588a542620e16368e4fd1a"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "a6dc621f8fc4f4558cb22289986a4886fe9e64c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-16f26d4f7fb5>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/13\n",
      "57/57 [==============================] - 45s 788ms/step - loss: 0.6837 - accuracy: 0.6789 - val_loss: 5.9340 - val_accuracy: 0.4950\n",
      "Epoch 2/13\n",
      "57/57 [==============================] - 44s 778ms/step - loss: 0.5539 - accuracy: 0.7411 - val_loss: 4.0491 - val_accuracy: 0.4750\n",
      "Epoch 3/13\n",
      "57/57 [==============================] - 44s 777ms/step - loss: 0.5386 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7650\n",
      "Epoch 4/13\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.7628\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "57/57 [==============================] - 44s 778ms/step - loss: 0.5282 - accuracy: 0.7628 - val_loss: 0.6242 - val_accuracy: 0.7000\n",
      "Epoch 5/13\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4870 - accuracy: 0.7867\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "57/57 [==============================] - 44s 770ms/step - loss: 0.4870 - accuracy: 0.7867 - val_loss: 0.5223 - val_accuracy: 0.7300\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\n",
    "reducel = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=13,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "8c8099fc4994ae9792c74477711794c83db3aeee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-9ef77cca6d77>:5: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8065000000000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make a prediction\n",
    "y_pred_keras = model.predict_generator(test_gen, steps=len(df_val), verbose=1)\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "auc_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f755d935752d007d21a59ac111cd0d604880c5fa"
   },
   "source": [
    "# Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "2397d1c4956ea8615140b9cc40bb857e8a5deeae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d52bccbbd7d4a8114b5bc9f53ce26db2601fa238"
   },
   "source": [
    "# Load test data and predict\n",
    "I could not find a smart way to do this without crashing the Kernel (due to MemoryError). So I just load the test files in batches, predict, and concatenate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "357d239024be4067fa88d87ca0dc0202a59b9d1b"
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ccdefc4770fa3b4d57c56990105173161471420"
   },
   "outputs": [],
   "source": [
    "base_test_dir = 'test/'\n",
    "test_files = glob(os.path.join(base_test_dir,'*.tif'))\n",
    "submission = pd.DataFrame()\n",
    "file_batch = 5000\n",
    "max_idx = len(test_files)\n",
    "for idx in range(0, max_idx, file_batch):\n",
    "    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "    test_df['image'] = test_df['path'].map(imread)\n",
    "    K_test = np.stack(test_df[\"image\"].values)\n",
    "    K_test = (K_test - K_test.mean()) / K_test.std()\n",
    "    predictions = model.predict(K_test)\n",
    "    test_df['label'] = predictions\n",
    "    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0c095619c41eb1996612d96e1ec3b147ebbe601"
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "# Delete the test_dir directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree(train_path)\n",
    "shutil.rmtree(valid_path)\n",
    "submission.to_csv(\"submission.csv\", index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
